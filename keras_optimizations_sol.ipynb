{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PTC5srJ2bYG9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras import Sequential\n",
        "#from tensorflow.keras import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, InputLayer, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kt2r1tfRg0cj"
      },
      "outputs": [],
      "source": [
        "# Helper to plot loss\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8tDLiFbYG_"
      },
      "source": [
        "# Keras and Tensorflow Optimizations\n",
        "\n",
        "There are several things that we can do to make our networks a bit better. Unfortunately for much of this there aren't definitive answers for \"what is the best choice\", so we do have to do some trial and error, but we can use some guidelines to get us started in the right direction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQLYUA1XbYHB"
      },
      "source": [
        "## Load MNIST Data\n",
        "\n",
        "We can use the MNIST digit dataset for testing, since it is reasonably large. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGygrQlobYHC",
        "outputId": "e48ea85c-2032-4ddc-85bf-4a02dd76b7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 15s 8ms/step - loss: 0.2218 - accuracy: 0.9341 - val_loss: 0.1195 - val_accuracy: 0.9653\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0889 - accuracy: 0.9732 - val_loss: 0.0889 - val_accuracy: 0.9732\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0573 - accuracy: 0.9824 - val_loss: 0.0933 - val_accuracy: 0.9718\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.0839 - val_accuracy: 0.9750\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0832 - val_accuracy: 0.9780\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0807 - val_accuracy: 0.9794\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0904 - val_accuracy: 0.9766\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.1079 - val_accuracy: 0.9756\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0947 - val_accuracy: 0.9783\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0889 - val_accuracy: 0.9797\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0745 - accuracy: 0.9824\n",
            "[0.07446283102035522, 0.9824000000953674]\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "print(train_images.shape)\n",
        "\n",
        "train_labels = np_utils.to_categorical(train_labels)\n",
        "test_labels = np_utils.to_categorical(test_labels)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsycEGiGbYHE"
      },
      "source": [
        "## Prequel - Saving and Loading Models\n",
        "\n",
        "As we've seen, models can take a long time to train in many cases. Like with the sklearn models, we can save and load ours as they are trained and reused. This is a pretty integral part of making neural network models usable, so it is pretty easy. \n",
        "\n",
        "In addition to this we often see models saved in the h5 format, which just saves slightly less stuff along with the model. If we are using models trained elsewhere this format is very common. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2PSIZDbbYHE",
        "outputId": "37aa2093-e7d5-4680-fac9-ba4045372d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_path/assets\n"
          ]
        }
      ],
      "source": [
        "# Save my model\n",
        "model.save('model_path')\n",
        "model = keras.models.load_model('model_path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lEJgmNFYbYHE"
      },
      "outputs": [],
      "source": [
        "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
        "model.save(\"my_h5_model.h5\")\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoRkV4nTbYHF"
      },
      "source": [
        "## Network Size\n",
        "\n",
        "Probably the first question that we will think of when building networks through Tensorflow is \"how big should it be\"? This is a very big question, and one of those ones without a real answer. We can put some guidelines in place to help us though. \n",
        "\n",
        "### What Does the Size Mean?\n",
        "\n",
        "The size of a neural network is also known as the capacity. We can relate it roughly to the size of our first model, the tree. The larger a network is the higher its capacity to learn. \n",
        "\n",
        "### What Size to Use\n",
        "\n",
        "We can start with a few guidelines to have a reasonably sized neural network. These steps do not ensure an optimal solution, but they'll get us started. There really is not a prescribed method for calculating the optimal network size (beleive me, I've looked), but there are several rules of thumb we can build together:\n",
        "\n",
        "<ul>\n",
        "<li> Start with an input layer that is either\n",
        "    <ul>\n",
        "    <li> The width of the data, if the feature set is relatively small. \n",
        "    <li> A reasonably large number if the feature set is large. \n",
        "    <li> We don't have a true diving line, but 512 is a reasonable value to try for an upper end, at least at first. \n",
        "    </ul>\n",
        "<li> Add 1 or 2 hidden layers of the same size and observe the results. We want to keep the model smaller if making it larger doesn't improve things, so first we shoudl see how good of a job a small model does. If the data is very large, skipping past the 1 layer step may save some time since we can predict that we can do better with a larger model in advance. \n",
        "<li> Increase layers of the same size until we get some overfitting and the training loss flattens. We want to reach the point where the model is getting to be excellent at predicting the training data. This is something we can see in the plot by noticing that the validation loss flatlines or starts to get worse. The training loss flattening is an indication that the model is not getting any better at learning the training data; we can use early stopping with a loose patience setting on training loss and lots of epochs to find this. \n",
        "<li> Add regularization steps to cut down that overfitting. We can try regularization and dropouts to cut down on that overfitting. We probably want to try a few options, parameters, and combinations here, there's not really a way to know in advance which regularization will work best on our data. \n",
        "<li> \"Funnel\" the layer size, potentially adding more layers. The traditional configuration of layers is to gradually decrease the size from the input layer towards the output layer. There is open debate on if this is better than having layers that are all the same size. We can play with this a little to see if results improve or not. \n",
        "<li> Use pruning. Much like a tree we can prune back a model to fight overfitting. \n",
        "</ul>\n",
        "\n",
        "### Height vs Width\n",
        "\n",
        "Another begged question is should we make networks wider (more neurons) or deeper (more layers)? Once again, there's no universal answer, but the general evidence leans towards more layers. There are several reasons for this, none of them definitive, but taken as a whole they add up to a strong case:\n",
        "\n",
        "<ul>\n",
        "<li> Ability to learn different representation of the data - this will be more clear next time when we start to look at some image specific neural networks, but one of the cool features of neural networks is that at each layer the network \"sees\" a different representation of the data, as it goes through each round of transformations. This has the effect of allowing it to identify different features at each layer, and use those features to make more and more accurate predictions. We'll examine this more soon. \n",
        "<li> Avoiding overfitting - extremely wide neural networks tend towards overfitting the training data and not generalizing as well to new data. \n",
        "<li> Ability to add interim steps - with a multi layer network we can add multiple steps such as regularization or dropouts, again to fight overfitting. \n",
        "<li> Automatic feature selection - deep neural networks will automatically perform a type of feature selection as the least important features are minimized in their importance. This is an emerging area of research - some people have argued that well designed neural networks can remove the need for feature selection, and neural networks are being created to be feature selection tools. We can see this illustrated most clearly with images again, we feed a network an entire image, and get a prediction. Note that this isn't a total rejection of feature selection for neural networks, improving the feature set will impact neural network models just as it will for ordinary models; with neural networks we just have the potential for the network to \"cover for mistakes\" in the features. This is more dramatic as data size and network size increase. \n",
        "<li> Results - deep learning has become a common term recently for a reason, due to the success of deep neural networks with many layers. Most of the cool stuff that we see coming from AI such as image recognition, translation, and self navigating robots are the result of deep learning networks. In practice these networks have tended to outperform shallower ones, especially in more complex tasks. \n",
        "</ul>\n",
        "\n",
        "Why not make a model that is both very wide and very deep? This will tend to overfit as it can \"memorize\" the training data. With large datasets we do see very large models in some cases, since the more data we have, the more fitting we can handle. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-CRvieaiZI2",
        "outputId": "8c109988-428d-481d-d54e-b8eb1954cb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2253 - accuracy: 0.9311 - val_loss: 0.1218 - val_accuracy: 0.9638\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1082 - accuracy: 0.9663 - val_loss: 0.1053 - val_accuracy: 0.9712\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0805 - accuracy: 0.9754 - val_loss: 0.0951 - val_accuracy: 0.9722\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 0.0935 - val_accuracy: 0.9758\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0598 - accuracy: 0.9816 - val_loss: 0.0841 - val_accuracy: 0.9773\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0539 - accuracy: 0.9841 - val_loss: 0.0995 - val_accuracy: 0.9750\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.1023 - val_accuracy: 0.9751\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.0922 - val_accuracy: 0.9796\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 0.1080 - val_accuracy: 0.9760\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.1130 - val_accuracy: 0.9773\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4adadcf650>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Big Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(784, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(784, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJkWGpsmbYHG",
        "outputId": "cda23fac-98c0-4d7d-d016-56d69a369bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2860 - accuracy: 0.9128 - val_loss: 0.1227 - val_accuracy: 0.9650\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1487 - accuracy: 0.9575 - val_loss: 0.1382 - val_accuracy: 0.9607\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1219 - accuracy: 0.9660 - val_loss: 0.1097 - val_accuracy: 0.9692\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0987 - accuracy: 0.9729 - val_loss: 0.1189 - val_accuracy: 0.9706\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0868 - accuracy: 0.9754 - val_loss: 0.1103 - val_accuracy: 0.9723\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0866 - accuracy: 0.9767 - val_loss: 0.1234 - val_accuracy: 0.9722\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0713 - accuracy: 0.9801 - val_loss: 0.1159 - val_accuracy: 0.9740\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.1409 - val_accuracy: 0.9717\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0651 - accuracy: 0.9829 - val_loss: 0.1205 - val_accuracy: 0.9741\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0602 - accuracy: 0.9840 - val_loss: 0.1175 - val_accuracy: 0.9765\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4adac2cfd0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Big Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmRw70jwga-g",
        "outputId": "c6dacb57-0449-40b7-e461-457f48745d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3934 - accuracy: 0.8860 - val_loss: 0.1647 - val_accuracy: 0.9519\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1698 - accuracy: 0.9566 - val_loss: 0.1172 - val_accuracy: 0.9693\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1400 - accuracy: 0.9647 - val_loss: 0.1142 - val_accuracy: 0.9702\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1150 - accuracy: 0.9689 - val_loss: 0.1036 - val_accuracy: 0.9737\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0969 - accuracy: 0.9744 - val_loss: 0.1084 - val_accuracy: 0.9736\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0892 - accuracy: 0.9762 - val_loss: 0.1045 - val_accuracy: 0.9738\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0779 - accuracy: 0.9795 - val_loss: 0.0994 - val_accuracy: 0.9768\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0706 - accuracy: 0.9818 - val_loss: 0.1299 - val_accuracy: 0.9717\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0645 - accuracy: 0.9836 - val_loss: 0.1425 - val_accuracy: 0.9748\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0621 - accuracy: 0.9836 - val_loss: 0.1110 - val_accuracy: 0.9764\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4adaa62890>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tapered Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwRjUyBMbYHG"
      },
      "source": [
        "## Epochs and Batch Sizes\n",
        "\n",
        "### Epochs\n",
        "\n",
        "Each epoch is a run through all of the training data. Epochs are simple, we can set a large number and use early stopping to cut things off when we've reached the best result. \n",
        "\n",
        "### Batch Sizes\n",
        "\n",
        "Batch size determines how many records are processed before the gradients are updated - i.e. the number of records between one forward and backwards pass.\n",
        "\n",
        "The batch sizes are a matter of very open debate for the optimal solution. At the high end, batch sizes are limited by what can fit in memory. When dealing with very large data this may matter as a batch that is a small fraction of the data may be a massive absolute size. At the lower end using smaller batches gives the same effect as it does when we looked at regular gradient descent - the gradients become less stable as we are relying on a smaller number of records. In reading more about batch sizes I want to update my recommendation to be even smaller than the 50 to 150 I suggested before, down to less than 100, even as small as into the single digits. There is research that smaller batch sizes tend to produce models that generalize better than ones with larger batches. \n",
        "\n",
        "Larger batch sizes do tend to be processed more quickly, sometimes substantially so, as the hardware is better able to be \"saturated\" with data to process. \n",
        "\n",
        "Dont' stress too much on batch size, this is really something that needs to be grid searched to find a great answer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMFYDxPdbYHG",
        "outputId": "bff27c4c-5d53-4d25-96f5-ef5c69444d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 1.3632 - accuracy: 0.6243 - val_loss: 0.4708 - val_accuracy: 0.8644\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.4782 - accuracy: 0.8542 - val_loss: 0.3032 - val_accuracy: 0.9104\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.3432 - accuracy: 0.8988 - val_loss: 0.2371 - val_accuracy: 0.9313\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.2675 - accuracy: 0.9210 - val_loss: 0.2031 - val_accuracy: 0.9408\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.2285 - accuracy: 0.9333 - val_loss: 0.1755 - val_accuracy: 0.9490\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1935 - accuracy: 0.9426 - val_loss: 0.1575 - val_accuracy: 0.9544\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1706 - accuracy: 0.9490 - val_loss: 0.1425 - val_accuracy: 0.9594\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.1520 - accuracy: 0.9552 - val_loss: 0.1315 - val_accuracy: 0.9618\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.1361 - accuracy: 0.9601 - val_loss: 0.1230 - val_accuracy: 0.9643\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.1247 - accuracy: 0.9642 - val_loss: 0.1163 - val_accuracy: 0.9655\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ada7b9710>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Big Batch\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  batch_size=5000,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbJeAtnDipXo",
        "outputId": "e5abf716-b380-4174-f0df-9611e7689a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24000/24000 [==============================] - 112s 5ms/step - loss: 0.3057 - accuracy: 0.9136 - val_loss: 0.1563 - val_accuracy: 0.9572\n",
            "Epoch 2/10\n",
            "24000/24000 [==============================] - 111s 5ms/step - loss: 0.2223 - accuracy: 0.9451 - val_loss: 0.1787 - val_accuracy: 0.9571\n",
            "Epoch 3/10\n",
            "24000/24000 [==============================] - 111s 5ms/step - loss: 0.2160 - accuracy: 0.9524 - val_loss: 0.1620 - val_accuracy: 0.9632\n",
            "Epoch 4/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.2002 - accuracy: 0.9563 - val_loss: 0.1707 - val_accuracy: 0.9657\n",
            "Epoch 5/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.2018 - accuracy: 0.9581 - val_loss: 0.1623 - val_accuracy: 0.9679\n",
            "Epoch 6/10\n",
            "24000/24000 [==============================] - 111s 5ms/step - loss: 0.1947 - accuracy: 0.9603 - val_loss: 0.2034 - val_accuracy: 0.9685\n",
            "Epoch 7/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.1987 - accuracy: 0.9609 - val_loss: 0.1991 - val_accuracy: 0.9702\n",
            "Epoch 8/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.1911 - accuracy: 0.9615 - val_loss: 0.1996 - val_accuracy: 0.9711\n",
            "Epoch 9/10\n",
            "24000/24000 [==============================] - 110s 5ms/step - loss: 0.1874 - accuracy: 0.9633 - val_loss: 0.2039 - val_accuracy: 0.9697\n",
            "Epoch 10/10\n",
            "24000/24000 [==============================] - 101s 4ms/step - loss: 0.1963 - accuracy: 0.9640 - val_loss: 0.2380 - val_accuracy: 0.9728\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ad7eb0e90>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Small Batch\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  batch_size=2,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUFvtavwbYHH"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "Of all options the optimizer is the one we will care about the least. Each different optimizer is a different algorithm for doing the gradient descent. The optimizers have different results with respect to speed, memory usage, computational expense, and likelyhood to get stuck in a local minima. \n",
        "\n",
        "Adam is a good compromise between all factors and is very commonly used. We'll just use this for our work. One other common one is RMSprop, if you're feeling spicy, give that a try and see if there are any imporvements. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5qIRrRF2bYHH"
      },
      "outputs": [],
      "source": [
        "optimizer_1 = tf.keras.optimizers.Adam()\n",
        "optimizer_2 = tf.keras.optimizers.RMSprop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXb18AySbYHH"
      },
      "source": [
        "## Activation \n",
        "\n",
        "Activation functions are the key to adding non-linearity to the network allowing it to learn complex and non-linear relationships in the data. We've used ReLU as the default and that is a solid choice in most cases. \n",
        "\n",
        "ReLU has one issue, the dying ReLU problem. This can happen when we get inputs to the activation function fall in the negative area. In short there can be neurons that \"die\" and never get updated again. \n",
        "\n",
        "To combat the dying ReLU problem there are a couple of other activation functions that avoid that issue - Leaky ReLU and ELU. Each one changes the negative values to something other than 0 - Leaky ReLU uses a slight linear gradient, ELU uses an exponential function for a similar, but curved, slight gradient. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ81hFfxbYHH",
        "outputId": "d9a522ce-4252-4709-cb3a-c5cebfb1f355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2731 - accuracy: 0.9181 - val_loss: 0.1513 - val_accuracy: 0.9543\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.1348 - accuracy: 0.9581 - val_loss: 0.1184 - val_accuracy: 0.9633\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1060 - accuracy: 0.9666 - val_loss: 0.1175 - val_accuracy: 0.9663\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0905 - accuracy: 0.9720 - val_loss: 0.0970 - val_accuracy: 0.9725\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0760 - accuracy: 0.9760 - val_loss: 0.0910 - val_accuracy: 0.9744\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.1130 - val_accuracy: 0.9689\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.1047 - val_accuracy: 0.9716\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0576 - accuracy: 0.9819 - val_loss: 0.1050 - val_accuracy: 0.9748\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0606 - accuracy: 0.9812 - val_loss: 0.1068 - val_accuracy: 0.9725\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0560 - accuracy: 0.9826 - val_loss: 0.1116 - val_accuracy: 0.9725\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ad74e5650>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a leak \n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='leaky_relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='leaky_relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi7DxgCsbYHH"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "The initialization provides the starting point for all the weights and bias values that we start out with. We initially started with random values in the scratch network - this is generally fine, but we can sometimes do better. \n",
        "\n",
        "### Imbalanced Weighting\n",
        "\n",
        "One application where initialization can help significantly is when dealing with imbalanced data. In this example of credit card fraud (real data that has been put through PCA), very, very few transactions are fraudulent. So we have a very imbalanced target value. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "jf84UJGPbYHI",
        "outputId": "8293e2c9-d3ae-45d7-a10d-30eeeeb95c1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6177101d-b415-47a4-97a1-9116d7f46065\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6177101d-b415-47a4-97a1-9116d7f46065')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6177101d-b415-47a4-97a1-9116d7f46065 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6177101d-b415-47a4-97a1-9116d7f46065');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = tf.keras.utils\n",
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count the Target Outcomes\n",
        "\n",
        "Credit card fraud is relatively rare, at least in view of the total number of transactions. We can count up the target values to see exactly what the expected skew is. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec08WeQEi_Fz",
        "outputId": "c35fb180-9017-4304-ce29-fd36ca25bfc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples:\n",
            "    Total: 284807\n",
            "    Positive: 492 (0.17% of total)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "neg, pos = np.bincount(raw_df['Class'])\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gr-lqY0tHwp"
      },
      "source": [
        "### We Have an Imbalance\n",
        "\n",
        "A big one. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5S02N45tGfu",
        "outputId": "27b8e170-e838-4c7d-adf1-b9013e4f9a6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0              0.0\n",
              "1              0.0\n",
              "2              1.0\n",
              "3              1.0\n",
              "4              2.0\n",
              "            ...   \n",
              "284802    172786.0\n",
              "284803    172787.0\n",
              "284804    172788.0\n",
              "284805    172788.0\n",
              "284806    172792.0\n",
              "Name: Time, Length: 284807, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_df = raw_df.copy()\n",
        "\n",
        "# You don't want the `Time` column.\n",
        "cleaned_df.pop('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-3538h2djFHF"
      },
      "outputs": [],
      "source": [
        "# Use a utility from sklearn to split and shuffle your dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Class'))\n",
        "test_labels = np.array(test_df.pop('Class'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "test_features = np.array(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC5P3kaBjMwN",
        "outputId": "ed06c86d-234b-4045-b4fc-1c117eddf35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features shape: (227845, 29)\n",
            "Training labels shape: (227845,)\n",
            "Test features shape: (56962, 29)\n",
            "Test labels shape: (56962,)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "#train_features = np.clip(train_features, -5, 5)\n",
        "#test_features = np.clip(test_features, -5, 5)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Test features shape:', test_features.shape)\n",
        "print('Test labels shape:', test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtt_zz0HA6Jp"
      },
      "source": [
        "### Create a Biased Model\n",
        "\n",
        "As a side note, we can also specify a lot of different metrics to return, if we want to. \n",
        "\n",
        "The bias of the data is inserted in the model compilation step on the output layer. What does this do? It preconfigures the output layer to \"expect\" results to be this skewed. Recall that, along with the weight, the bias values are one of the things that is learned in training. By default the initial values are randomized, so the model needs to learn the skew towards the imbalance - if the balance between classes is moderate, that's not a big deal; if the balance is so drastically skewed in one direction, that's less practical. With the preset bias we can speed convergance and likely reduce loss. \n",
        "\n",
        "#### Other Imbalenced Work\n",
        "\n",
        "Other things that we looked at to improve balance such as under/over sampling still works with neural networks as it would with anything else. This is just one nn-specific thing that we can implement with minimal extra work. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO7R0L7XjTZv",
        "outputId": "1344b694-02cc-4855-8d0a-30cd56f4e6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2849/2849 [==============================] - 34s 10ms/step - loss: 0.0060 - tp: 150.0000 - fp: 31.0000 - tn: 181931.0000 - fn: 164.0000 - accuracy: 0.9989 - precision: 0.8287 - recall: 0.4777 - auc: 0.9005 - prc: 0.5935 - val_loss: 0.0029 - val_tp: 51.0000 - val_fp: 6.0000 - val_tn: 45496.0000 - val_fn: 16.0000 - val_accuracy: 0.9995 - val_precision: 0.8947 - val_recall: 0.7612 - val_auc: 0.9325 - val_prc: 0.7801\n",
            "Epoch 2/10\n",
            "2849/2849 [==============================] - 26s 9ms/step - loss: 0.0046 - tp: 177.0000 - fp: 37.0000 - tn: 181925.0000 - fn: 137.0000 - accuracy: 0.9990 - precision: 0.8271 - recall: 0.5637 - auc: 0.9257 - prc: 0.6744 - val_loss: 0.0026 - val_tp: 45.0000 - val_fp: 5.0000 - val_tn: 45497.0000 - val_fn: 22.0000 - val_accuracy: 0.9994 - val_precision: 0.9000 - val_recall: 0.6716 - val_auc: 0.9326 - val_prc: 0.8127\n",
            "Epoch 3/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0043 - tp: 195.0000 - fp: 35.0000 - tn: 181927.0000 - fn: 119.0000 - accuracy: 0.9992 - precision: 0.8478 - recall: 0.6210 - auc: 0.9210 - prc: 0.6941 - val_loss: 0.0029 - val_tp: 39.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 28.0000 - val_accuracy: 0.9993 - val_precision: 0.9286 - val_recall: 0.5821 - val_auc: 0.9326 - val_prc: 0.8129\n",
            "Epoch 4/10\n",
            "2849/2849 [==============================] - 27s 10ms/step - loss: 0.0042 - tp: 186.0000 - fp: 24.0000 - tn: 181938.0000 - fn: 128.0000 - accuracy: 0.9992 - precision: 0.8857 - recall: 0.5924 - auc: 0.9273 - prc: 0.7161 - val_loss: 0.0026 - val_tp: 53.0000 - val_fp: 8.0000 - val_tn: 45494.0000 - val_fn: 14.0000 - val_accuracy: 0.9995 - val_precision: 0.8689 - val_recall: 0.7910 - val_auc: 0.9325 - val_prc: 0.8001\n",
            "Epoch 5/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0041 - tp: 196.0000 - fp: 38.0000 - tn: 181924.0000 - fn: 118.0000 - accuracy: 0.9991 - precision: 0.8376 - recall: 0.6242 - auc: 0.9339 - prc: 0.6924 - val_loss: 0.0025 - val_tp: 44.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 23.0000 - val_accuracy: 0.9994 - val_precision: 0.9362 - val_recall: 0.6567 - val_auc: 0.9326 - val_prc: 0.8254\n",
            "Epoch 6/10\n",
            "2849/2849 [==============================] - 37s 13ms/step - loss: 0.0041 - tp: 192.0000 - fp: 34.0000 - tn: 181928.0000 - fn: 122.0000 - accuracy: 0.9991 - precision: 0.8496 - recall: 0.6115 - auc: 0.9306 - prc: 0.7141 - val_loss: 0.0026 - val_tp: 45.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 22.0000 - val_accuracy: 0.9995 - val_precision: 0.9375 - val_recall: 0.6716 - val_auc: 0.9326 - val_prc: 0.8245\n",
            "Epoch 7/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0039 - tp: 190.0000 - fp: 33.0000 - tn: 181929.0000 - fn: 124.0000 - accuracy: 0.9991 - precision: 0.8520 - recall: 0.6051 - auc: 0.9355 - prc: 0.7171 - val_loss: 0.0025 - val_tp: 46.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 21.0000 - val_accuracy: 0.9995 - val_precision: 0.9388 - val_recall: 0.6866 - val_auc: 0.9326 - val_prc: 0.8229\n",
            "Epoch 8/10\n",
            "2849/2849 [==============================] - 35s 12ms/step - loss: 0.0036 - tp: 208.0000 - fp: 31.0000 - tn: 181931.0000 - fn: 106.0000 - accuracy: 0.9992 - precision: 0.8703 - recall: 0.6624 - auc: 0.9451 - prc: 0.7607 - val_loss: 0.0024 - val_tp: 53.0000 - val_fp: 6.0000 - val_tn: 45496.0000 - val_fn: 14.0000 - val_accuracy: 0.9996 - val_precision: 0.8983 - val_recall: 0.7910 - val_auc: 0.9326 - val_prc: 0.8267\n",
            "Epoch 9/10\n",
            "2849/2849 [==============================] - 34s 12ms/step - loss: 0.0036 - tp: 208.0000 - fp: 29.0000 - tn: 181933.0000 - fn: 106.0000 - accuracy: 0.9993 - precision: 0.8776 - recall: 0.6624 - auc: 0.9339 - prc: 0.7555 - val_loss: 0.0023 - val_tp: 50.0000 - val_fp: 3.0000 - val_tn: 45499.0000 - val_fn: 17.0000 - val_accuracy: 0.9996 - val_precision: 0.9434 - val_recall: 0.7463 - val_auc: 0.9326 - val_prc: 0.8326\n",
            "Epoch 10/10\n",
            "2849/2849 [==============================] - 27s 9ms/step - loss: 0.0039 - tp: 191.0000 - fp: 36.0000 - tn: 181926.0000 - fn: 123.0000 - accuracy: 0.9991 - precision: 0.8414 - recall: 0.6083 - auc: 0.9418 - prc: 0.7210 - val_loss: 0.0023 - val_tp: 52.0000 - val_fp: 4.0000 - val_tn: 45498.0000 - val_fn: 15.0000 - val_accuracy: 0.9996 - val_precision: 0.9286 - val_recall: 0.7761 - val_auc: 0.9326 - val_prc: 0.8329\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ad7279990>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "\n",
        "#def make_model(metrics=METRICS, output_bias=None):\n",
        "initial_bias = np.log([pos/neg])\n",
        "\n",
        "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(16, activation='relu',input_shape=(train_features.shape[-1],)))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias))\n",
        "\n",
        "#model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=metrics)\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=METRICS)\n",
        "#Fit\n",
        "model.fit(\n",
        "  train_features,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_features, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdPzxFgXbYHI"
      },
      "source": [
        "## Pruning\n",
        "\n",
        "We can also use pruning to improve our networks, which is built into Tensorflow and is similar in concept to the tree pruning we did earlier. \n",
        "\n",
        "### Pruning Results\n",
        "\n",
        "Pruning removes the least useful weights, increasing sparsity. These sparse models require less processing (since many calculations will be M * 0) and may be compressed down to take less space in memory. \n",
        "\n",
        "### Smaller Models\n",
        "\n",
        "One other consideration is that we can use pruning to create smaller models that are better able to be executed on weaker hardware. In the context of a full computer, creating a prediction with a neural network is pretty fast. If we want to move the model to small embedded devices though, the memory and processing needs can still be excessive. \n",
        "\n",
        "Some scenarios where this comes up are things like security cameras that can recognize images, robots that can navigate themselves, or evern small computers like a Raspberry Pi. This challenge is magnified if you are dealing with something like video, which can generate 30+ images per second. Small models that are almost as good, but can be run with less compouting power allow the power of neural networks to be expanded to more devices - train on a powerful computer, us on a small and weak computer.\n",
        "\n",
        "We can use the tflite set of tools to create special models that are optimized for lower computing power devices, though we won't explore that here. \n",
        "\n",
        "**Note:** pruning is largely a step that is for deployment of models, as we can make the processing more efficient and the memory required lesser. For us, it isn't the most critical of steps. In general, a smaller model that produces the same or similar accuracy is better, as you can do more with less. The reduction of overfitting and potential accuracy benefits are somewhat secondary to making the model more usable in practice. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FzYRlh3vtFH",
        "outputId": "3c0d4f0e-029d-4ae8-a0c9-4509b947f236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.21.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_model_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrXm0AC9bYHI",
        "outputId": "72e2ad31-aa4f-4760-d10c-615ce87eb5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_dense_2  (None, 16)               946       \n",
            " 5 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dropout  (None, 16)               1         \n",
            " _17 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_2  (None, 1)                35        \n",
            " 6 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 982\n",
            "Trainable params: 497\n",
            "Non-trainable params: 485\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  trainable=False)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "model_for_pruning = prune_low_magnitude(model)\n",
        "\n",
        "\n",
        "model_for_pruning.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=METRICS)\n",
        "\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3sPhB8EbYHI",
        "outputId": "be02d7f7-896a-4d1b-8041-6f476ee62c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2849/2849 [==============================] - 37s 12ms/step - loss: 0.0070 - tp: 165.0000 - fp: 20.0000 - tn: 227444.0000 - fn: 216.0000 - accuracy: 0.9990 - precision: 0.8919 - recall: 0.4331 - auc: 0.7699 - prc: 0.5033 - val_loss: 0.0042 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9178 - val_prc: 0.8041\n",
            "Epoch 2/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0065 - tp: 126.0000 - fp: 17.0000 - tn: 181945.0000 - fn: 188.0000 - accuracy: 0.9989 - precision: 0.8811 - recall: 0.4013 - auc: 0.7370 - prc: 0.4301 - val_loss: 0.0042 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9326 - val_prc: 0.8188\n",
            "Epoch 3/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0064 - tp: 123.0000 - fp: 14.0000 - tn: 181948.0000 - fn: 191.0000 - accuracy: 0.9989 - precision: 0.8978 - recall: 0.3917 - auc: 0.8383 - prc: 0.4415 - val_loss: 0.0038 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9325 - val_prc: 0.8255\n",
            "Epoch 4/10\n",
            "2849/2849 [==============================] - 32s 11ms/step - loss: 0.0060 - tp: 139.0000 - fp: 15.0000 - tn: 181947.0000 - fn: 175.0000 - accuracy: 0.9990 - precision: 0.9026 - recall: 0.4427 - auc: 0.9281 - prc: 0.4781 - val_loss: 0.0034 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 56.0000 - val_accuracy: 0.9988 - val_precision: 1.0000 - val_recall: 0.1642 - val_auc: 0.9474 - val_prc: 0.8312\n",
            "Epoch 5/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0059 - tp: 136.0000 - fp: 20.0000 - tn: 181942.0000 - fn: 178.0000 - accuracy: 0.9989 - precision: 0.8718 - recall: 0.4331 - auc: 0.9348 - prc: 0.4667 - val_loss: 0.0040 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9473 - val_prc: 0.8275\n",
            "Epoch 6/10\n",
            "2849/2849 [==============================] - 31s 11ms/step - loss: 0.0063 - tp: 118.0000 - fp: 17.0000 - tn: 181945.0000 - fn: 196.0000 - accuracy: 0.9988 - precision: 0.8741 - recall: 0.3758 - auc: 0.9441 - prc: 0.4302 - val_loss: 0.0038 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 65.0000 - val_accuracy: 0.9986 - val_precision: 1.0000 - val_recall: 0.0299 - val_auc: 0.9473 - val_prc: 0.8323\n",
            "Epoch 7/10\n",
            "2849/2849 [==============================] - 33s 12ms/step - loss: 0.0059 - tp: 127.0000 - fp: 9.0000 - tn: 181953.0000 - fn: 187.0000 - accuracy: 0.9989 - precision: 0.9338 - recall: 0.4045 - auc: 0.9480 - prc: 0.4596 - val_loss: 0.0030 - val_tp: 24.0000 - val_fp: 0.0000e+00 - val_tn: 45502.0000 - val_fn: 43.0000 - val_accuracy: 0.9991 - val_precision: 1.0000 - val_recall: 0.3582 - val_auc: 0.9474 - val_prc: 0.8347\n",
            "Epoch 8/10\n",
            "2849/2849 [==============================] - ETA: 0s - loss: 0.0060 - tp: 123.0000 - fp: 18.0000 - tn: 181944.0000 - fn: 191.0000 - accuracy: 0.9989 - precision: 0.8723 - recall: 0.3917 - auc: 0.9417 - prc: 0.4512"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_features, train_labels,\n",
        "                  batch_size=64, epochs=10, validation_split=.2,\n",
        "                  callbacks=callbacks)\n",
        "model_for_pruning.evaluate(test_features, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "keras_optimizations_sol.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit (conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
